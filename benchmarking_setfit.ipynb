{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "%cd /content/drive/MyDrive/aml_final/aml_final/\n",
    "! git pull\n",
    "! pip install setfit\n",
    "'''\n",
    "\n",
    "import torch, gc\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "\n",
    "from train.reporter import Reporter\n",
    "from train.metrics import comprehensive_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "full_train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "reporter = Reporter(\"model_comparison.csv\")\n",
    "\n",
    "num_classes = 6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_random_subset(dataset: Dataset, num_samples: int = 16) -> Dataset:\n",
    "    subset = dataset.shuffle().select(range(num_samples))\n",
    "    if len(set(subset[\"label\"])) < num_classes:\n",
    "        print(\"Shit happens\")\n",
    "        return create_random_subset(dataset, num_samples)\n",
    "    return subset\n",
    "\n",
    "\n",
    "def create_train_sets(full_train_dataset: Dataset, num_samples: int = 16):\n",
    "    full_train_dataset = full_train_dataset.shuffle()\n",
    "    small_dataset = sample_dataset(full_train_dataset, label_column=\"label\", num_samples=num_samples//num_classes)\n",
    "    unbalanced_0 = full_train_dataset.filter(lambda e: e[\"label\"]==0).select(range(num_samples))\n",
    "    unbalanced_1 = full_train_dataset.filter(lambda e: e[\"label\"]==1).select(range(num_samples))\n",
    "    big_dataset = concatenate_datasets([small_dataset, unbalanced_0, unbalanced_1])\n",
    "    unbalanced_0 = concatenate_datasets([small_dataset, unbalanced_0])\n",
    "    unbalanced_1 = concatenate_datasets([small_dataset, unbalanced_1])\n",
    "    random_subset = create_random_subset(big_dataset, num_samples=num_samples)\n",
    "    return small_dataset, unbalanced_0, unbalanced_1, big_dataset, random_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(dataset: Dataset, reporter: Reporter, model_name: str):\n",
    "    args = TrainingArguments(num_iterations=20)\n",
    "    model_init = lambda: SetFitModel.from_pretrained(\n",
    "        model_name,\n",
    "        use_differentiable_head=True,\n",
    "        head_params={\"out_features\": num_classes}\n",
    "        ).to(device)\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=args,\n",
    "        metric=comprehensive_metrics,\n",
    "        column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    "    )\n",
    "    trainer.train()\n",
    "    reporter.report(trainer, dataset, model_name=model_name)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 8\n",
    "for seed in range(5):\n",
    "    dataset = sample_dataset(full_train_dataset, num_samples=num_samples, seed=seed)\n",
    "    for model_name in [\"sentence-transformers/all-mpnet-base-v2\", \"WhereIsAI/UAE-Large-V1\"]:\n",
    "        run_train(dataset, reporter, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 64\n",
    "for seed in range(5):\n",
    "    dataset = sample_dataset(full_train_dataset, num_samples=num_samples, seed=seed)\n",
    "    for model_name in [\"sentence-transformers/all-mpnet-base-v2\", \"WhereIsAI/UAE-Large-V1\"]:\n",
    "        run_train(dataset, reporter, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
